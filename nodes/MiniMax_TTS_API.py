# MiniMax_TTS_API.py
from __future__ import annotations
import os
import json
import requests
import torch
import io
from datetime import datetime
import folder_paths
from ..register import register_node
import soundfile as sf
import re

# ========== å®˜æ–¹ 80 ç§ä¸»éŸ³è‰² IDï¼ˆ2025-12 æ›´æ–°ï¼‰ ==========
VOICE_PRESETS = [
    "male-qn-qingse",        # 01 é’æ¶©é’å¹´        ä¸­æ–‡
    "male-qn-jingying",      # 02 ç²¾è‹±é’å¹´        ä¸­æ–‡
    "male-qn-badao",         # 03 éœ¸é“é’å¹´        ä¸­æ–‡
    "male-qn-daxuesheng",    # 04 é’å¹´å¤§å­¦ç”Ÿ      ä¸­æ–‡
    "female-shaonv",         # 05 å°‘å¥³            ä¸­æ–‡
    "female-yujie",          # 06 å¾¡å§            ä¸­æ–‡
    "female-chengshu",       # 07 æˆç†Ÿå¥³æ€§        ä¸­æ–‡
    "female-tianmei",        # 08 ç”œç¾å¥³æ€§        ä¸­æ–‡
    "male-qn-qingse-jingpin", # 09 é’æ¶©é’å¹´-b      ä¸­æ–‡
    "male-qn-jingying-jingpin", #10 ç²¾è‹±é’å¹´-b      ä¸­æ–‡
    "male-qn-badao-jingpin", # 11 éœ¸é“é’å¹´-b      ä¸­æ–‡
    "male-qn-daxuesheng-jingpin", #12 å¤§å­¦ç”Ÿ-b      ä¸­æ–‡
    "female-shaonv-jingpin", # 13 å°‘å¥³-b          ä¸­æ–‡
    "female-yujie-jingpin",  # 14 å¾¡å§-b          ä¸­æ–‡
    "female-chengshu-jingpin", #15 æˆç†Ÿå¥³-b        ä¸­æ–‡
    "female-tianmei-jingpin", #16 ç”œç¾å¥³-b        ä¸­æ–‡
    "clever_boy",            # 17 èªæ˜ç”·ç«¥        ä¸­æ–‡
    "cute_boy",              # 18 å¯çˆ±ç”·ç«¥        ä¸­æ–‡
    "lovely_girl",           # 19 èŒèŒå¥³ç«¥        ä¸­æ–‡
    "cartoon_pig",           # 20 å¡é€šçŒªå°çª      ä¸­æ–‡
    "bingjiao_didi",         # 21 ç—…å¨‡å¼Ÿå¼Ÿ        ä¸­æ–‡
    "junlang_nanyou",        # 22 ä¿Šæœ—ç”·å‹        ä¸­æ–‡
    "chunzhen_xuedi",        # 23 çº¯çœŸå­¦å¼Ÿ        ä¸­æ–‡
    "lengdan_xiongzhang",    # 24 å†·æ·¡å­¦é•¿        ä¸­æ–‡
    "badao_shaoye",          # 25 éœ¸é“å°‘çˆ·        ä¸­æ–‡
    "tianxin_xiaoling",      # 26 ç”œå¿ƒå°ç²        ä¸­æ–‡
    "qiaopi_mengmei",        # 27 ä¿çš®èŒå¦¹        ä¸­æ–‡
    "wumei_yujie",           # 28 å¦©åªšå¾¡å§        ä¸­æ–‡
    "diadia_xuemei",         # 29 å—²å—²å­¦å¦¹        ä¸­æ–‡
    "danya_xuejie",          # 30 æ·¡é›…å­¦å§        ä¸­æ–‡
    "Chinese (Mandarin)_Reliable_Executive",      # 31 æ²‰ç¨³é«˜ç®¡        ä¸­æ–‡
    "Chinese (Mandarin)_News_Anchor",             # 32 æ–°é—»å¥³å£°        ä¸­æ–‡
    "Chinese (Mandarin)_Mature_Woman",            # 33 å‚²å¨‡å¾¡å§        ä¸­æ–‡
    "Chinese (Mandarin)_Unrestrained_Young_Man",  # 34 ä¸ç¾é’å¹´        ä¸­æ–‡
    "Arrogant_Miss",                              # 35 åš£å¼ å°å§        ä¸­æ–‡
    "Robot_Armor",                                # 36 æœºæ¢°æˆ˜ç”²        ä¸­æ–‡
    "Chinese (Mandarin)_Kind-hearted_Antie",      # 37 çƒ­å¿ƒå¤§å©¶        ä¸­æ–‡
    "Chinese (Mandarin)_HK_Flight_Attendant",     # 38 æ¸¯æ™®ç©ºå§        ä¸­æ–‡
    "Chinese (Mandarin)_Humorous_Elder",          # 39 æç¬‘å¤§çˆ·        ä¸­æ–‡
    "Chinese (Mandarin)_Gentleman",               # 40 æ¸©æ¶¦ç”·å£°        ä¸­æ–‡
    "Chinese (Mandarin)_Warm_Bestie",             # 41 æ¸©æš–é—ºèœœ        ä¸­æ–‡
    "Chinese (Mandarin)_Male_Announcer",          # 42 æ’­æŠ¥ç”·å£°        ä¸­æ–‡
    "Chinese (Mandarin)_Sweet_Lady",              # 43 ç”œç¾å¥³å£°        ä¸­æ–‡
    "Chinese (Mandarin)_Southern_Young_Man",      # 44 å—æ–¹å°å“¥        ä¸­æ–‡
    "Chinese (Mandarin)_Wise_Women",              # 45 é˜…å†å§å§        ä¸­æ–‡
    "Chinese (Mandarin)_Gentle_Youth",            # 46 æ¸©æ¶¦é’å¹´        ä¸­æ–‡
    "Chinese (Mandarin)_Warm_Girl",               # 47 æ¸©æš–å°‘å¥³        ä¸­æ–‡
    "Chinese (Mandarin)_Kind-hearted_Elder",      # 48 èŠ±ç”²å¥¶å¥¶        ä¸­æ–‡
    "Chinese (Mandarin)_Cute_Spirit",             # 49 æ†¨æ†¨èŒå…½        ä¸­æ–‡
    "Chinese (Mandarin)_Radio_Host",              # 50 ç”µå°ç”·ä¸»æ’­      ä¸­æ–‡
    "Chinese (Mandarin)_Lyrical_Voice",           # 51 æŠ’æƒ…ç”·å£°        ä¸­æ–‡
    "Chinese (Mandarin)_Straightforward_Boy",     # 52 ç‡çœŸå¼Ÿå¼Ÿ        ä¸­æ–‡
    "Chinese (Mandarin)_Sincere_Adult",           # 53 çœŸè¯šé’å¹´        ä¸­æ–‡
    "Chinese (Mandarin)_Gentle_Senior",           # 54 æ¸©æŸ”å­¦å§        ä¸­æ–‡
    "Chinese (Mandarin)_Stubborn_Friend",         # 55 å˜´ç¡¬ç«¹é©¬        ä¸­æ–‡
    "Chinese (Mandarin)_Crisp_Girl",              # 56 æ¸…è„†å°‘å¥³        ä¸­æ–‡
    "Chinese (Mandarin)_Pure-hearted_Boy",        # 57 æ¸…æ¾ˆé‚»å®¶å¼Ÿ      ä¸­æ–‡
    "Chinese (Mandarin)_Soft_Girl",               # 58 è½¯è½¯å¥³å­©        ä¸­æ–‡
    "Cantonese_ProfessionalHostï¼ˆF)",             # 59 ç²¤æ™®å¥³ä¸»æŒ      ç²¤è¯­
    "Cantonese_GentleLady",                       # 60 ç²¤è¯­æ¸©æŸ”å¥³      ç²¤è¯­
    "Cantonese_ProfessionalHostï¼ˆM)",             # 61 ç²¤æ™®ç”·ä¸»æŒ      ç²¤è¯­
    "Cantonese_PlayfulMan",                       # 62 ç²¤è¯­æ´»æ³¼ç”·      ç²¤è¯­
    "Cantonese_CuteGirl",                         # 63 ç²¤è¯­å¯çˆ±å¥³      ç²¤è¯­
    "Cantonese_KindWoman",                        # 64 ç²¤è¯­å–„è‰¯å¥³      ç²¤è¯­
    "Santa_Claus",                                # 65 åœ£è¯è€äºº        è‹±æ–‡
    "Grinch",                                     # 66 æ ¼æ—å¥‡          è‹±æ–‡
    "Rudolph",                                    # 67 é²é“å¤«          è‹±æ–‡
    "Arnold",                                     # 68 é˜¿è¯ºå¾·          è‹±æ–‡
    "Charming_Santa",                             # 69 é­…åŠ›åœ£è¯è€äºº    è‹±æ–‡
    "Charming_Lady",                              # 70 é­…åŠ›å¥³å£«        è‹±æ–‡
    "Sweet_Girl",                                 # 71 ç”œç¾å¥³å­©        è‹±æ–‡
    "Cute_Elf",                                   # 72 å¯çˆ±ç²¾çµ        è‹±æ–‡
    "Attractive_Girl",                            # 73 é­…åŠ›å¥³å­©        è‹±æ–‡
    "Serene_Woman",                               # 74 å®é™å¥³å£«        è‹±æ–‡
    "English_Trustworthy_Man",                    # 75 å¯ä¿¡ç”·å£«        è‹±æ–‡
    "English_Graceful_Lady",                      # 76 ä¼˜é›…å¥³å£«        è‹±æ–‡
    "English_Aussie_Bloke",                       # 77 æ¾³æ´²ç”·å£«        è‹±æ–‡
    "English_Whispering_girl",                    # 78 è€³è¯­å°‘å¥³        è‹±æ–‡
    "English_Diligent_Man",                       # 79 å‹¤å¥‹ç”·å£«        è‹±æ–‡
    "English_Gentle-voiced_man",                  # 80 æ¸©æŸ”ç”·å£°        è‹±æ–‡
]


# ========== èŠ‚ç‚¹1: å•éŸ³è‰²TTS ==========
class MiniMaxTTS:
    DESCRIPTION = (
        "ğŸ’• Aiya MiniMax TTSï¼ˆspeech-2.6-hdï¼‰\n\n"
        "ã€åŠŸèƒ½ã€‘è¾“å…¥æ–‡æœ¬ â†’ è¾“å‡ºæ ‡å‡† AUDIO å¼ é‡ï¼ŒèŠ‚ç‚¹è‡ªèº«é›¶è½ç›˜ï¼Œä¸‹æ¸¸éšæ„ä¿å­˜/é¢„è§ˆ\n"
        "ã€å¿…å¡«ã€‘API å¯†é’¥ & åˆæˆæ–‡æœ¬ï¼›å…¶ä½™å‚æ•°æŒ‰éœ€è°ƒèŠ‚\n"
        "ã€éŸ³è‰²ã€‘80 ç§å®˜æ–¹ä¸»éŸ³è‰²ï¼ˆä¸­è‹±ç²¤å…¨è¦†ç›–ï¼‰ï¼Œå…¶ä½™ ID å·²ä¸‹æ¶\n"
        "ã€æ¨¡å‹ã€‘æ”¯æŒ speech-2.6-hd ç­‰æ¨¡å‹ï¼Œå¯æ‰‹åŠ¨è¾“å…¥\n"
        "ã€å‚æ•°ã€‘è¯­é€Ÿ 0.5-2Ã—ã€éŸ³é«˜ Â±12ã€éŸ³é‡ 0-10ã€æƒ…ç»ª 6 ç§ã€é‡‡æ ·ç‡ 16k/24k/48k\n"
        "ã€è¾“å‡ºã€‘audio(1,1,N) æ ‡å‡† dict + info å­—ç¬¦ä¸²ï¼ˆéŸ³è‰²/æ¨¡å‹/å¤§å°ç­‰ï¼‰\n"
        "ã€è¿æ¥ã€‘æ–°å¢ voice_in å­—ç¬¦ä¸²å£ï¼š\n"
        "â€ƒâ€ƒâ‘  æœ‰è¿çº¿ â†’ ä¼˜å…ˆä½¿ç”¨ä¸Šæ¸¸éŸ³è‰²ï¼ˆå¦‚ç‹¬ç«‹éŸ³è‰²é€‰æ‹©å™¨ï¼‰\n"
        "â€ƒâ€ƒâ‘¡ æ— è¿çº¿ â†’ å›è½åˆ°è‡ªèº« voice_id ä¸‹æ‹‰æ¡†\n"
        "ã€å¼‚å¸¸ã€‘ä»»ä½•é”™è¯¯å‡è¿”å›åˆæ³•ç©ºéŸ³é¢‘ï¼Œä¸‹æ¸¸ä¸å´©ï¼›çœ‹ info ç«¯å£æç¤º\n\n"
        "========== å®˜æ–¹éŸ³è‰²é€ŸæŸ¥è¡¨ï¼ˆå¤åˆ¶åˆ°æ–‡æœ¬èŠ‚ç‚¹æŸ¥çœ‹ï¼‰ ==========\n"
        "01  male-qn-qingse                     é’æ¶©é’å¹´        ä¸­æ–‡\n"
        "02  male-qn-jingying                   ç²¾è‹±é’å¹´        ä¸­æ–‡\n"
        "08  female-tianmei                     ç”œç¾å¥³æ€§        ä¸­æ–‡ï¼ˆé»˜è®¤ï¼‰\n"
        "14  female-yujie-jingpin               å¾¡å§-b          ä¸­æ–‡\n"
        "31  Chinese (Mandarin)_Reliable_Executive      æ²‰ç¨³é«˜ç®¡        ä¸­æ–‡\n"
        "41  Chinese (Mandarin)_Warm_Bestie             æ¸©æš–é—ºèœœ        ä¸­æ–‡\n"
        "59  Cantonese_GentleLady                       ç²¤è¯­æ¸©æŸ”å¥³      ç²¤è¯­\n"
        "65  Santa_Claus                                åœ£è¯è€äºº        è‹±æ–‡\n"
        "80  English_Gentle-voiced_man                  æ¸©æŸ”ç”·å£°        è‹±æ–‡"
    )

    RETURN_TYPES = ("AUDIO", "STRING")
    RETURN_NAMES = ("éŸ³é¢‘", "info")
    FUNCTION = "generate_speech"
    CATEGORY = "å“å‘€âœ¦MMX/TTS"
    OUTPUT_NODE = True

    def __init__(self):
        self.output_dir = folder_paths.get_output_directory()

    @staticmethod
    def extract_voice_id(display: str) -> str:
        return display

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {
                    "default": "",
                    "placeholder": "sk-***************************"
                }),
                "api_url": ("STRING", {
                    "default": "https://www.dmxapi.cn/v1/audio/speech",
                    "placeholder": "APIè¯·æ±‚åœ°å€"
                }),
                "model": ("STRING", {
                    "default": "speech-2.6-hd",
                    "placeholder": "æ¨¡å‹åç§°ï¼Œå¦‚ï¼šspeech-2.6-hd"
                }),
                "text": ("STRING", {
                    "multiline": True,
                    "default": "Hello, this is a test. ä½ å¥½ï¼Œæµ‹è¯•å®Œæ¯•ã€‚",
                    "placeholder": "Text to synthesize"
                }),
                "voice_id": (VOICE_PRESETS, {
                    "default": "female-tianmei-jingpin"
                }),
                "speed": ("FLOAT", {
                    "default": 1.0,
                    "min": 0.5,
                    "max": 2.0,
                    "step": 0.05,
                    "display": "slider"
                }),
                "pitch": ("INT", {
                    "default": 0,
                    "min": -12,
                    "max": 12,
                    "step": 1,
                    "display": "slider"
                }),
                "volume": ("FLOAT", {
                    "default": 1.0,
                    "min": 0.0,
                    "max": 10.0,
                    "step": 0.1,
                    "display": "slider"
                }),
                "emotion": (["neutral", "happy", "sad", "angry", "fearful", "surprised"], {
                    "default": "neutral"
                }),
                "audio_format": (["mp3", "wav"], {
                    "default": "mp3"
                }),
                "sample_rate": ("INT", {
                    "default": 24000,
                    "min": 16000,
                    "max": 48000,
                    "step": 8000
                }),
            },
            "optional": {
                "voice_in": ("STRING", {
                    "default": "",
                    "placeholder": "å¤–éƒ¨éŸ³è‰²IDï¼ˆè¿çº¿æ—¶ä¼˜å…ˆï¼‰"
                }),
                "custom_voice_id": ("STRING", {
                    "default": "",
                    "placeholder": "Custom voice IDï¼ˆå¤‡ç”¨ï¼‰"
                }),
            }
        }

    @staticmethod
    def audio_bytes_to_tensor(data: bytes, ext: str, target_sr: int = 24000):
        wav, sr = sf.read(io.BytesIO(data))  # (N,) or (N, 2)
        if wav.ndim == 2:
            wav = wav.mean(-1)
        if sr != target_sr:
            import librosa
            wav = librosa.resample(wav, orig_sr=sr, target_sr=target_sr)
        tensor = torch.from_numpy(wav).unsqueeze(0).unsqueeze(0)  # (1, 1, N)
        return tensor, target_sr

    def generate_speech(
        self,
        api_key,
        api_url,
        model,
        text,
        voice_id,
        speed,
        pitch,
        volume,
        emotion,
        audio_format,
        sample_rate,
        voice_in="",
        custom_voice_id="",
    ):
        # ===== 1. åŸºæœ¬æ ¡éªŒ =====
        if not api_key.strip():
            return ({"waveform": torch.zeros(1, 1, 1), "sample_rate": 24000}, "âŒ API Key ä¸ºç©º")
        if not text.strip():
            return ({"waveform": torch.zeros(1, 1, 1), "sample_rate": 24000}, "âŒ åˆæˆæ–‡æœ¬ ä¸ºç©º")
        
        # ===== 2. å¤„ç†API URL =====
        final_api_url = api_url.strip()
        if not final_api_url:
            final_api_url = "https://www.dmxapi.cn/v1/audio/speech"
            
        # ===== 3. å¤„ç†æ¨¡å‹åç§° =====
        final_model = model.strip()
        if not final_model:
            final_model = "speech-2.6-hd"

        # ===== 4. éŸ³è‰²ä¼˜å…ˆçº§ï¼švoice_in > custom_voice_id > voice_id ä¸‹æ‹‰æ¡† =====
        if voice_in.strip():                      # â‘  å¤–éƒ¨è¿çº¿ä¼˜å…ˆ
            final_voice_id = self.extract_voice_id(voice_in)
        elif custom_voice_id.strip():             # â‘¡ å¤‡ç”¨è‡ªå®šä¹‰
            final_voice_id = self.extract_voice_id(custom_voice_id)
        else:                                     # â‘¢ å›è½è‡ªèº«ä¸‹æ‹‰æ¡†
            final_voice_id = self.extract_voice_id(voice_id)

        headers = {
            "Authorization": f"Bearer {api_key.strip()}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": final_model,
            "input": text,
            "voice": final_voice_id,
            "output_format": "url",
            "speed": speed,
            "voice_setting": {
                "voice_id": final_voice_id,
                "speed": speed,
                "pitch": pitch,
                "emotion": emotion,
                "volume": volume,
            },
            "audio_setting": {
                "sample_rate": sample_rate,
                "format": audio_format,
            },
        }

        try:
            print(f"[MiniMax TTS] æ­£åœ¨ç”Ÿæˆè¯­éŸ³...")
            print(f"  APIåœ°å€: {final_api_url}")
            print(f"  æ¨¡å‹: {final_model}")
            print(f"  æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
            print(f"  éŸ³è‰²ID: {final_voice_id}")

            response = requests.post(final_api_url, headers=headers, json=payload, timeout=120)
            print(f"[MiniMax TTS] HTTP {response.status_code}")

            if response.status_code != 200:
                err_info = f"âŒ API é”™è¯¯ {response.status_code}: {response.text[:300]}"
                print(err_info)
                return ({"waveform": torch.zeros(1, 1, 1), "sample_rate": 24000}, err_info)

            # ===== å–éŸ³é¢‘æ•°æ® =====
            audio_data = None
            audio_url = response.headers.get("Audio-Url") or response.headers.get("audio-url")
            if audio_url:
                print(f"[MiniMax TTS] ä»å“åº”å¤´å–å¾—éŸ³é¢‘URL: {audio_url}")
                r = requests.get(audio_url, timeout=60)
                if r.status_code != 200:
                    err = f"âŒ ä¸‹è½½éŸ³é¢‘å¤±è´¥: {r.status_code}"
                    return ({"waveform": torch.zeros(1, 1, 1), "sample_rate": 24000}, err)
                audio_data = r.content
            else:
                body = response.content
                ct = response.headers.get("Content-Type", "")
                if ct.startswith("audio/") or body.startswith((b"ID3", b"RIFF", b"\xFF\xFB", b"\xFF\xF3", b"\xFF\xE3")):
                    print("[MiniMax TTS] æ£€æµ‹åˆ°bodyä¸ºéŸ³é¢‘äºŒè¿›åˆ¶ï¼Œç›´æ¥ä½¿ç”¨")
                    audio_data = body
                else:
                    try:
                        result = response.json()
                        url = result.get("audio", {}).get("url")
                        if url:
                            print(f"[MiniMax TTS] ä»JSONå–å¾—éŸ³é¢‘URL: {url}")
                            r = requests.get(url, timeout=60)
                            if r.status_code != 200:
                                err = f"âŒ ä¸‹è½½éŸ³é¢‘å¤±è´¥: {r.status_code}"
                                return ({"waveform": torch.zeros(1, 1, 1), "sample_rate": 24000}, err)
                            audio_data = r.content
                        else:
                            return ({"waveform": torch.zeros(1, 1, 1), "sample_rate": 24000}, "âŒ æœªæ‰¾åˆ°éŸ³é¢‘URL")
                    except ValueError as e:
                        return ({"waveform": torch.zeros(1, 1, 1), "sample_rate": 24000}, f"âŒ è¿”å›ä½“ä¸æ˜¯åˆæ³•JSON: {e}")

            if audio_data is None:
                return ({"waveform": torch.zeros(1, 1, 1), "sample_rate": 24000}, "âŒ æ— æ³•è·å–éŸ³é¢‘æ•°æ®")

            # ===== æ­£å¸¸è¿”å› =====
            waveform, sr = self.audio_bytes_to_tensor(audio_data, audio_format, sample_rate)
            audio_dict = {"waveform": waveform, "sample_rate": sr}
            info_str = (
                f"API: {final_api_url} | voice: {voice_id} | model: {final_model} | "
                f"speed: {speed} | pitch: {pitch} | emotion: {emotion} | "
                f"sample_rate: {sr} | format: {audio_format} | "
                f"size: {len(audio_data)} bytes"
            )
            print(f"[MiniMax TTS] âœ… éŸ³é¢‘å·²å°±ç»ªï¼Œæ•°æ®é•¿åº¦: {len(audio_data)} bytes")
            return (audio_dict, info_str)

        except requests.exceptions.Timeout:
            return ({"waveform": torch.zeros(1, 1, 1), "sample_rate": 24000}, "âŒ è¯·æ±‚è¶…æ—¶ (120s)")
        except Exception as e:
            import traceback
            traceback.print_exc()
            err = f"âŒ é”™è¯¯: {str(e)}"
            print(err)
            return ({"waveform": torch.zeros(1, 1, 1), "sample_rate": 24000}, err)


# ========== èŠ‚ç‚¹2: å¤šäººå¯¹è¯TTS ==========
class MiniMaxTTSMultiChar:
    DESCRIPTION = (
        "ğŸ’• MiniMax å¤šäººå¯¹è¯ TTSï¼ˆspeech-2.6-hdï¼‰\n\n"
        "ã€ç”¨æ³•ã€‘\n"
        "1) script ç«¯å£æ¯è¡Œæ ¼å¼ï¼š\n"
        "     è§’è‰²|è¯­é€Ÿ|éŸ³é«˜|æƒ…ç»ª:æ–‡æœ¬   ï¼ˆåä¸‰é¡¹å¯çœç•¥ï¼Œé»˜è®¤ 1.0/0/neutralï¼‰\n"
        "   ä¾‹ï¼š\n"
        "     å°æ˜|1.2:ä»Šå¤©æˆ‘ä»¬å»åƒç«é”…å§ï¼\n"
        "     å°çº¢|0.9|+2|happy:è¶…å¼€å¿ƒï¼\n"
        "     å°åˆš:æˆ‘å°±ç”¨é»˜è®¤å‚æ•°\n"
        "2) voice_map ç«¯å£å†™ã€Œè§’è‰²=éŸ³è‰²IDã€æ˜ å°„ï¼Œä¸€è¡Œä¸€æ¡ã€‚\n"
        "3) å…¶ä½™å‚æ•°ï¼ˆé‡‡æ ·ç‡ã€æ ¼å¼ç­‰ï¼‰å…¨å±€é»˜è®¤ï¼›å•ç‹¬å†™çš„ä¼˜å…ˆçº§>å…¨å±€ã€‚\n"
        "4) è¾“å‡ºä¸€æ¡æ‹¼æ¥å¥½çš„é•¿éŸ³é¢‘ + æ¯å¥ infoï¼ˆæ¢è¡Œåˆ†éš”ï¼‰ã€‚\n"
        "5) ä»»æ„å¥å­åˆæˆå¤±è´¥è‡ªåŠ¨æ’å…¥ 0.1 s é™éŸ³ï¼Œä¸‹æ¸¸æ°¸ä¸å´©æºƒã€‚\n"
    )

    RETURN_TYPES = ("AUDIO", "STRING")
    RETURN_NAMES = ("æ‹¼æ¥éŸ³é¢‘", "info")
    FUNCTION = "generate_multichar_speech"
    CATEGORY = "å“å‘€âœ¦MMX/TTS"
    OUTPUT_NODE = True

    def __init__(self):
        self.worker = MiniMaxTTS()

    # ---------------- å°å·¥å…· ----------------
    @staticmethod
    def _make_silence_tensor(sec: float, sr: int):
        """ç”Ÿæˆé™éŸ³å¼ é‡ï¼Œç¡®ä¿è¿”å›float32ç±»å‹"""
        n = int(sec * sr)
        return torch.zeros(1, 1, n, dtype=torch.float32)

    @staticmethod
    def _parse_script(script: str):
        """
        è§£æå‰§æœ¬
        æ¯è¡Œæ ¼å¼ï¼š  è§’è‰²|speed|pitch|emotion:æ–‡æœ¬
        è¿”å› List[Dict{'role','speed','pitch','emotion','text'}]
        ç¼ºçœå€¼ï¼šspeed=1.0  pitch=0  emotion='neutral'
        """
        lines = [ln.strip() for ln in script.splitlines() if ln.strip()]
        out = []
        for ln in lines:
            if ':' not in ln:
                continue
            head, txt = ln.split(':', 1)
            # é»˜è®¤å€¼
            role, speed, pitch, emotion = head.strip(), 1.0, 0, 'neutral'
            # æŒ‰ | æ‹†åˆ†æœ€å¤š 4 æ®µ
            parts = [p.strip() for p in head.split('|')]
            if len(parts) >= 1:
                role = parts[0]
            if len(parts) >= 2:
                try:
                    speed = float(parts[1])
                except ValueError:
                    speed = 1.0
            if len(parts) >= 3:
                try:
                    pitch = int(parts[2])
                except ValueError:
                    pitch = 0
            if len(parts) >= 4:
                emotion = parts[3] if parts[3] in {"neutral", "happy", "sad", "angry", "fearful", "surprised"} else "neutral"
            out.append({"role": role, "speed": speed, "pitch": pitch, "emotion": emotion, "text": txt.strip()})
        return out

    @staticmethod
    def _parse_voice_map(voice_map: str):
        mp = {}
        for ln in voice_map.splitlines():
            ln = ln.strip()
            if not ln or '=' not in ln:
                continue
            role, vid = ln.split('=', 1)
            mp[role.strip()] = vid.strip()
        return mp

    # ---------------- è¾“å…¥ç«¯å£ ----------------
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {
                    "default": "", "placeholder": "sk-***************************"
                }),
                "api_url": ("STRING", {
                    "default": "https://www.dmxapi.cn/v1/audio/speech",
                    "placeholder": "APIè¯·æ±‚åœ°å€"
                }),
                "model": ("STRING", {
                    "default": "speech-2.6-hd",
                    "placeholder": "æ¨¡å‹åç§°ï¼Œå¦‚ï¼šspeech-2.6-hd"
                }),
                "script": ("STRING", {
                    "multiline": True,
                    "default": "å°æ˜|1.2:ä»Šå¤©æˆ‘ä»¬å»åƒç«é”…å§ï¼\nå°çº¢|0.9:è¶…å¼€å¿ƒï¼\nå°åˆš:æˆ‘å°±ç”¨é»˜è®¤å‚æ•°",
                    "placeholder": "è§’è‰²|speed|pitch|emotion:æ–‡æœ¬  ï¼ˆåä¸‰é¡¹å¯çœç•¥ï¼‰"
                }),
                "voice_map": ("STRING", {
                    "multiline": True,
                    "default": "å°æ˜=male-qn-qingse\nå°çº¢=female-tianmei\nå°åˆš=male-qn-jingying",
                    "placeholder": "è§’è‰²=éŸ³è‰²ID  ä¸€è¡Œä¸€æ¡"
                }),
                "speed": ("FLOAT", {
                    "default": 1.0, "min": 0.5, "max": 2.0, "step": 0.05, "display": "slider"
                }),
                "pitch": ("INT", {
                    "default": 0, "min": -12, "max": 12, "step": 1, "display": "slider"
                }),
                "volume": ("FLOAT", {
                    "default": 1.0, "min": 0.0, "max": 10.0, "step": 0.1, "display": "slider"
                }),
                "emotion": (["neutral", "happy", "sad", "angry", "fearful", "surprised"], {"default": "neutral"}),
                "audio_format": (["mp3", "wav"], {"default": "mp3"}),
                "sample_rate": ("INT", {
                    "default": 24000, "min": 16000, "max": 48000, "step": 8000
                }),
            }
        }

    # ---------------- ä¸»å…¥å£ ----------------
    def generate_multichar_speech(
        self,
        api_key,
        api_url,
        model,
        script,
        voice_map,
        speed,
        pitch,
        volume,
        emotion,
        audio_format,
        sample_rate,
    ):
        # é”™è¯¯å¤„ç†ï¼šAPI Keyä¸ºç©º
        if not api_key.strip():
            silence = torch.zeros(1, 1, 1, dtype=torch.float32)
            return ({"waveform": silence, "sample_rate": 24000}, "âŒ API Key ä¸ºç©º")
        
        # å¤„ç†API URL
        final_api_url = api_url.strip()
        if not final_api_url:
            final_api_url = "https://www.dmxapi.cn/v1/audio/speech"
            
        # å¤„ç†æ¨¡å‹åç§°
        final_model = model.strip()
        if not final_model:
            final_model = "speech-2.6-hd"
        
        # è§£æå‰§æœ¬å’ŒéŸ³è‰²æ˜ å°„
        dialogue = self._parse_script(script)
        role2voice = self._parse_voice_map(voice_map)
        
        # é”™è¯¯å¤„ç†ï¼šå‰§æœ¬æˆ–æ˜ å°„ä¸ºç©º
        if not dialogue:
            silence = torch.zeros(1, 1, 1, dtype=torch.float32)
            return ({"waveform": silence, "sample_rate": sample_rate}, "âŒ å‰§æœ¬è§£æä¸ºç©º")
        if not role2voice:
            silence = torch.zeros(1, 1, 1, dtype=torch.float32)
            return ({"waveform": silence, "sample_rate": sample_rate}, "âŒ éŸ³è‰²æ˜ å°„ä¸ºç©º")

        wav_list, info_list = [], []
        
        # é€å¥å¤„ç†å¯¹è¯
        for idx, item in enumerate(dialogue, 1):
            role, text = item["role"], item["text"]
            
            # è·å–æœ¬å¥å‚æ•°ï¼ˆä¼˜å…ˆç”¨å‰§æœ¬é‡Œçš„ï¼Œå¦åˆ™ç”¨å…¨å±€é»˜è®¤ï¼‰
            spd = item.get("speed", speed)
            ptc = item.get("pitch", pitch)
            emo = item.get("emotion", emotion)
            
            # è·å–è§’è‰²å¯¹åº”çš„éŸ³è‰²ID
            voice_id = role2voice.get(role)
            if not voice_id:
                err = f"ç¬¬{idx}å¥è§’è‰²ã€{role}ã€æœªåœ¨ voice_map ä¸­æ‰¾åˆ°æ˜ å°„ï¼Œå·²æ’å…¥é™éŸ³"
                info_list.append(err)
                wav_list.append(self._make_silence_tensor(0.1, sample_rate))
                continue

            # è°ƒç”¨å•éŸ³è‰²åˆæˆèŠ‚ç‚¹
            audio_dict, info = self.worker.generate_speech(
                api_key=api_key,
                api_url=final_api_url,
                model=final_model,
                text=text,
                voice_id=voice_id,
                speed=spd,
                pitch=ptc,
                volume=volume,
                emotion=emo,
                audio_format=audio_format,
                sample_rate=sample_rate,
            )
            
            # å¤„ç†åˆæˆç»“æœ
            if "âŒ" in info:
                # åˆæˆå¤±è´¥ï¼Œæ’å…¥é™éŸ³
                wav_list.append(self._make_silence_tensor(0.1, sample_rate))
                info_list.append(f"ç¬¬{idx}å¥({role}) å¤±è´¥: {info}")
            else:
                # åˆæˆæˆåŠŸï¼Œç¡®ä¿éŸ³é¢‘æ˜¯float32ç±»å‹
                waveform = audio_dict["waveform"]
                if isinstance(waveform, torch.Tensor):
                    waveform = waveform.float()  # å¼ºåˆ¶è½¬æ¢ä¸ºfloat32
                wav_list.append(waveform)
                info_list.append(f"#{idx}({role}|spd={spd}|ptc={ptc}|emo={emo}) {info}")

        # æ‹¼æ¥æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ
        if wav_list:
            # ç¡®ä¿æ‰€æœ‰å¼ é‡éƒ½æ˜¯float32ç±»å‹
            wav_list = [wav.float() if isinstance(wav, torch.Tensor) else wav for wav in wav_list]
            full_wave = torch.cat(wav_list, dim=-1)
        else:
            # å¦‚æœæ²¡æœ‰éŸ³é¢‘ç‰‡æ®µï¼Œè¿”å›é™éŸ³
            full_wave = self._make_silence_tensor(1.0, sample_rate)
        
        # æœ€ç»ˆç¡®è®¤æ•°æ®ç±»å‹ä¸ºfloat32ï¼ˆComfyUIæ ‡å‡†ï¼‰
        full_wave = full_wave.float()
        
        # æ„é€ ComfyUIæ ‡å‡†çš„éŸ³é¢‘è¾“å‡ºå­—å…¸
        final_audio = {
            "waveform": full_wave,      # shape: (1, 1, n_samples), dtype: float32
            "sample_rate": sample_rate   # é‡‡æ ·ç‡
        }
        
        # ç”Ÿæˆä¿¡æ¯è¾“å‡º
        final_info = "\n".join(info_list)
        
        return (final_audio, final_info)


# ========== èŠ‚ç‚¹3: éŸ³è‰²é€‰æ‹©å™¨ ==========
class MiniMaxVoicePicker:
    DESCRIPTION = (
        "ğŸ’• å“å‘€âœ¦MiniMax éŸ³è‰²é€‰æ‹©å™¨\n\n"
        "ã€ç”¨é€”ã€‘å•ç‹¬è¾“å‡ºä¸€ä¸ª voice_id å­—ç¬¦ä¸²ï¼Œå¯è¿æ¥ä¸‹æ¸¸ TTS èŠ‚ç‚¹\n"
        "ã€åˆ—è¡¨ã€‘80 ç§å®˜æ–¹ä¸»éŸ³è‰²ï¼ˆä¸­è‹±ç²¤å…¨è¦†ç›–ï¼‰ï¼Œä¸‹æ‹‰æ¡†å³æ‹¿å³ç”¨\n"
        "ã€è¿æ¥ã€‘å°†æœ¬èŠ‚ç‚¹è¾“å‡ºçš„ã€Œvoice_idã€æ¥å…¥ã€ŒMiniMax TTSã€çš„ custom_voice_id å£å³å¯ç”Ÿæ•ˆ\n"
        "ã€å¥½å¤„ã€‘â‘  å¤ç”¨éŸ³è‰² â‘¡ ä¸€é”®åˆ‡æ¢ â‘¢ å·¥ä½œæµæ›´ç›´è§‚"
    )

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("voice_in",)
    FUNCTION = "pick_voice"
    CATEGORY = "å“å‘€âœ¦MMX/TTS"

    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "éŸ³è‰²é€‰æ‹©": (VOICE_PRESETS, {
                    "default": "female-tianmei-jingpin",
                    "label": "å®˜æ–¹ä¸»éŸ³è‰²ï¼ˆ80 ç§ï¼‰"
                }),
            }
        }

    def pick_voice(self, éŸ³è‰²é€‰æ‹©):
        # ä¸‹æ‹‰æ¡†å€¼æœ¬èº«å°±æ˜¯åˆæ³• IDï¼Œç›´æ¥è¿”å›
        return (éŸ³è‰²é€‰æ‹©,)


# ========== æ³¨å†Œæ‰€æœ‰èŠ‚ç‚¹ ==========
register_node(MiniMaxTTS, "MiniMax TTS æ–‡å­—è½¬è¯­éŸ³")
register_node(MiniMaxTTSMultiChar, "MiniMax TTS å¤šäººå¯¹è¯")
register_node(MiniMaxVoicePicker, "MiniMax TTSéŸ³è‰²é€‰æ‹©å™¨")
